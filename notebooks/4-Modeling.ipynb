{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Modeling - Investigating San Francisco Housing Prices Through Police Incident Reports and 311 Cases<a id='Modeling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Contents<a id='1_Contents'></a>\n",
    "* [Modeling - Investigating San Francisco Housing Prices Through Police Incident Reports and 311 Cases](#Modeling)\n",
    "  * [1 Contents](#1_Contents)\n",
    "  * [2 Introduction](#2_Introduction)\n",
    "  * [3 Imports](#3_Imports)\n",
    "  * [4 Load The Data](#4_Load_The_Data)\n",
    "  * [5 Create Train and Test Splits](#5_Create_Train_and_Test_Splits)\n",
    "  * [6 Models](#6_Models)\n",
    "    * [6.0 Dummy Model 0 - Standard Scaler, PCA, DummyRegressor](#6.0_Model_0_-_StandardScaler_PCA_DummyRegressor)\n",
    "    * [6.1 Model 1 - Standard Scaler, PCA, Linear Regression](#6.1_Model_1_-_StandardScaler_PCA_LinearRegression)\n",
    "    * [6.2 Model 2 - Robust Scaler, PCA, Linear Regression](#6.2_Model_2_-_RobustScaler_PCA_LinearRegression)\n",
    "    * [6.3 Model 3 - Robust Scaler, SelectKBest, Linear Regression](#6.3_Model_3_-_RobustScaler_SelectKBest_LinearRegression)\n",
    "    * [6.4 Model 4 - Robust Scaler, PCA, Random Forest](#6.4_Model_4_-_RobustScaler_PCA_RandomForest)\n",
    "    * [6.5 Model 5 - Robust Scaler, PCA, Ridge](#6.5_Model_5_-_RobustScaler_PCA_Ridge)\n",
    "    * [6.6 Model 6 - Robust Scaler, PCA, Lasso](#6.6_Model_6_-_RobustScaler_PCA_Lasso)\n",
    "    * [6.7 Model 7 - Robust Scaler, PCA, LassoLars](#6.7_Model_7_-_RobustScaler_PCA_LassoLars)\n",
    "    * [6.8 Model 8 - Robust Scaler, PCA, ElasticNet](#6.8_Model_8_-_RobustScaler_PCA_ElasticNet)\n",
    "  * [7 Model Evaluation](#7_Model_Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Introduction<a id='2_Introduction'></a>\n",
    "\n",
    "In this notebook, we will build different machine learning models using hyperparameter tuning and compare them to determine the best model that most accurately predicts the relationship between San Francisco housing prices and police incident reports and 311 cases. \n",
    "\n",
    "We will use the file `Post_EDA_SF_Combined_SFPD_311_Housing.csv` that was created in our previous Jupyter Notebook, `2-Exploratory_Data_Analysis.ipynb`. This file contains all SF police incident reports, 311 cases, and housing sales data aggregated by month and by neighborhood, from January 2018 up to and including September 2020, wherein each row is an observation with a distinct pairing on month-year and each column represents a possible feature to be used in modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Imports<a id='3_Imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import scale, RobustScaler, StandardScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LassoLars, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Load The Data<a id='4_Load_The_Data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Post_EDA_SF_Combined_SFPD_311_Housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1188 entries, 0 to 1187\n",
      "Data columns (total 82 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   Year Month                                    1188 non-null   int64  \n",
      " 1   Neighborhood                                  1188 non-null   object \n",
      " 2   Arson                                         1188 non-null   int64  \n",
      " 3   Assault                                       1188 non-null   int64  \n",
      " 4   Burglary                                      1188 non-null   int64  \n",
      " 5   Case Closure                                  1188 non-null   int64  \n",
      " 6   Civil Sidewalks                               1188 non-null   int64  \n",
      " 7   Courtesy Report                               1188 non-null   int64  \n",
      " 8   Disorderly Conduct                            1188 non-null   int64  \n",
      " 9   Drug Offense                                  1188 non-null   int64  \n",
      " 10  Drug Violation                                1188 non-null   int64  \n",
      " 11  Embezzlement                                  1188 non-null   int64  \n",
      " 12  Family Offense                                1188 non-null   int64  \n",
      " 13  Fire Report                                   1188 non-null   int64  \n",
      " 14  Forgery And Counterfeiting                    1188 non-null   int64  \n",
      " 15  Fraud                                         1188 non-null   int64  \n",
      " 16  Gambling                                      1188 non-null   int64  \n",
      " 17  Homicide                                      1188 non-null   int64  \n",
      " 18  Human Trafficking (A), Commercial Sex Acts    1188 non-null   int64  \n",
      " 19  Human Trafficking (B), Involuntary Servitude  1188 non-null   int64  \n",
      " 20  Human Trafficking, Commercial Sex Acts        1188 non-null   int64  \n",
      " 21  Larceny Theft                                 1188 non-null   int64  \n",
      " 22  Liquor Laws                                   1188 non-null   int64  \n",
      " 23  Lost Property                                 1188 non-null   int64  \n",
      " 24  Malicious Mischief                            1188 non-null   int64  \n",
      " 25  Miscellaneous Investigation                   1188 non-null   int64  \n",
      " 26  Missing Person                                1188 non-null   int64  \n",
      " 27  Motor Vehicle Theft                           1188 non-null   int64  \n",
      " 28  Motor Vehicle Theft?                          1188 non-null   int64  \n",
      " 29  Non-Criminal                                  1188 non-null   int64  \n",
      " 30  Offences Against The Family And Children      1188 non-null   int64  \n",
      " 31  Other                                         1188 non-null   int64  \n",
      " 32  Other Miscellaneous                           1188 non-null   int64  \n",
      " 33  Other Offenses                                1188 non-null   int64  \n",
      " 34  Prostitution                                  1188 non-null   int64  \n",
      " 35  Rape                                          1188 non-null   int64  \n",
      " 36  Recovered Vehicle                             1188 non-null   int64  \n",
      " 37  Robbery                                       1188 non-null   int64  \n",
      " 38  Sex Offense                                   1188 non-null   int64  \n",
      " 39  Stolen Property                               1188 non-null   int64  \n",
      " 40  Suicide                                       1188 non-null   int64  \n",
      " 41  Suspicious                                    1188 non-null   int64  \n",
      " 42  Suspicious Occ                                1188 non-null   int64  \n",
      " 43  Traffic Collision                             1188 non-null   int64  \n",
      " 44  Traffic Violation Arrest                      1188 non-null   int64  \n",
      " 45  Vandalism                                     1188 non-null   int64  \n",
      " 46  Vehicle Impounded                             1188 non-null   int64  \n",
      " 47  Vehicle Misplaced                             1188 non-null   int64  \n",
      " 48  Warrant                                       1188 non-null   int64  \n",
      " 49  Weapons Carrying Etc                          1188 non-null   int64  \n",
      " 50  Weapons Offence                               1188 non-null   int64  \n",
      " 51  Weapons Offense                               1188 non-null   int64  \n",
      " 52  311 External Request                          1188 non-null   int64  \n",
      " 53  Abandoned Vehicle                             1188 non-null   int64  \n",
      " 54  Blocked Street or SideWalk                    1188 non-null   int64  \n",
      " 55  Catch Basin Maintenance                       1188 non-null   int64  \n",
      " 56  Color Curb                                    1188 non-null   int64  \n",
      " 57  DPW Volunteer Programs                        1188 non-null   int64  \n",
      " 58  Damaged Property                              1188 non-null   int64  \n",
      " 59  Encampments                                   1188 non-null   int64  \n",
      " 60  General Request                               1188 non-null   int64  \n",
      " 61  Graffiti                                      1188 non-null   int64  \n",
      " 62  Homeless Concerns                             1188 non-null   int64  \n",
      " 63  Illegal Postings                              1188 non-null   int64  \n",
      " 64  Litter Receptacles                            1188 non-null   int64  \n",
      " 65  MUNI Feedback                                 1188 non-null   int64  \n",
      " 66  Muni Employee Feedback                        1188 non-null   int64  \n",
      " 67  Muni Service Feedback                         1188 non-null   int64  \n",
      " 68  Noise Report                                  1188 non-null   int64  \n",
      " 69  Parking Enforcement                           1188 non-null   int64  \n",
      " 70  Rec and Park Requests                         1188 non-null   int64  \n",
      " 71  Residential Building Request                  1188 non-null   int64  \n",
      " 72  SFHA Requests                                 1188 non-null   int64  \n",
      " 73  Sewer Issues                                  1188 non-null   int64  \n",
      " 74  Sidewalk or Curb                              1188 non-null   int64  \n",
      " 75  Sign Repair                                   1188 non-null   int64  \n",
      " 76  Street Defects                                1188 non-null   int64  \n",
      " 77  Street and Sidewalk Cleaning                  1188 non-null   int64  \n",
      " 78  Streetlights                                  1188 non-null   int64  \n",
      " 79  Temporary Sign Request                        1188 non-null   int64  \n",
      " 80  Tree Maintenance                              1188 non-null   int64  \n",
      " 81  Median Sale Price                             1188 non-null   float64\n",
      "dtypes: float64(1), int64(80), object(1)\n",
      "memory usage: 761.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Create Train and Test Splits<a id='5_Create_Train_and_Test_Splits'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous notebook `3-Preprocessing_and_Training.ipynb`, we manually created the train and test splits so as to avoid data leakage.\n",
    "\n",
    "Here, we will split out 85% of the data into the training set, leaving 15% of the data in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest date: 201801 Latest date: 202009 Number of months: 33\n"
     ]
    }
   ],
   "source": [
    "# Look at how many months of data we have\n",
    "print('Earliest date:',df['Year Month'].min(), 'Latest date:', df['Year Month'].max(), 'Number of months:', len(df['Year Month'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will split the data with 28 months in train and 5 months in test, approx 85/15 train/test split\n",
    "train = df[df['Year Month'] < 202005]\n",
    "test = df[df['Year Month'] >= 202005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1008, 82), (180, 82))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set X to be all the features, and y to be the Median Sale Prince __in thousands of $__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns='Median Sale Price')\n",
    "X_test = test.drop(columns='Median Sale Price')\n",
    "y_train = train['Median Sale Price'] / 1000\n",
    "y_test = test['Median Sale Price'] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1008, 81), (180, 81))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1008,), (180,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1008, 79), (180, 79))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the 'Year Month' and 'Neighborhood' columns from the train/test data into ids_train and ids_test\n",
    "# and drop these from 'X_train' and 'X_test'\n",
    "ids_list = ['Year Month', 'Neighborhood']\n",
    "ids_train = X_train[ids_list]\n",
    "ids_test = X_test[ids_list]\n",
    "X_train.drop(columns=ids_list, inplace=True)\n",
    "X_test.drop(columns=ids_list, inplace=True)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Models<a id='6_Models'></a>\n",
    "\n",
    "We're ready to create and evaluate some models. In order to do this, for each model, we will create a pipeline, then pass it into `GridSearchCV` to determine our optimal parameters for that model.\n",
    "\n",
    "Each pipeline will consist of:\n",
    "  * scaler: since our features contain numbers that vary by orders of magniture, we must scale them in preparation for PCA\n",
    "  * dimensionality reducer (i.e. PCA, SelectKBest) : reduce dimensionality of the data or selectively choose features\n",
    "  * regressor: our prediction component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.0 Dummy Model 0 - Standard Scaler, PCA, DummyRegressor<a id='6.0_Model_0_-_StandardScaler_PCA_DummyRegressor'></a>\n",
    "\n",
    "Let's find a baseline with a `DummyRegressor`. In our previous notebook `3-Preprocessing_and_Training.ipynb`, we determined that when PCA n_components=4, 91.5% of the variance is already explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'standardscaler', 'pca', 'dummyregressor', 'standardscaler__copy', 'standardscaler__with_mean', 'standardscaler__with_std', 'pca__copy', 'pca__iterated_power', 'pca__n_components', 'pca__random_state', 'pca__svd_solver', 'pca__tol', 'pca__whiten', 'dummyregressor__constant', 'dummyregressor__quantile', 'dummyregressor__strategy'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_0 = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    PCA(n_components=4, random_state=42),\n",
    "    DummyRegressor() )\n",
    "pipe_0.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('pca',\n",
       "                                        PCA(n_components=4, random_state=42)),\n",
       "                                       ('dummyregressor', DummyRegressor())]),\n",
       "             param_grid={'dummyregressor__strategy': ['mean', 'median']})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_0 = {'dummyregressor__strategy': ['mean','median']}\n",
    "model_0 = GridSearchCV(pipe_0, param_grid_0, cv=5)\n",
    "model_0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0: Best Score: -0.0014654209162468846\n",
      "Model 0: Best Parameters: {'dummyregressor__strategy': 'mean'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 0: Best Score: \" + str(model_0.best_score_))\n",
    "print(\"Model 0: Best Parameters: \" + str(model_0.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Model 1 - Standard Scaler, PCA, Linear Regression<a id='6.1_Model_1_-_StandardScaler_PCA_LinearRegression'></a>\n",
    "\n",
    "Our first model uses a basic pipeline consisting of `StandardScaler`, `PCA`, and `LinearRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'standardscaler', 'pca', 'linearregression', 'standardscaler__copy', 'standardscaler__with_mean', 'standardscaler__with_std', 'pca__copy', 'pca__iterated_power', 'pca__n_components', 'pca__random_state', 'pca__svd_solver', 'pca__tol', 'pca__whiten', 'linearregression__copy_X', 'linearregression__fit_intercept', 'linearregression__n_jobs', 'linearregression__normalize'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_1 = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    PCA(random_state=42),\n",
    "    LinearRegression() )\n",
    "pipe_1.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('pca', PCA(random_state=42)),\n",
       "                                       ('linearregression',\n",
       "                                        LinearRegression())]),\n",
       "             param_grid={'pca__n_components': array([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_1 = {'pca__n_components': np.arange(4,20)}\n",
    "model_1 = GridSearchCV(pipe_1, param_grid_1, cv=5)\n",
    "model_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: Best Score: 0.2376077027842245\n",
      "Model 1: Best Parameters: {'pca__n_components': 17}\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 1: Best Score: \" + str(model_1.best_score_))\n",
    "print(\"Model 1: Best Parameters: \" + str(model_1.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Model 2 - Robust Scaler, PCA, Linear Regression<a id='6.2_Model_2_-_RobustScaler_PCA_LinearRegression'></a>\n",
    "\n",
    "Our second model will try to improve on the first by switching out the `StandardScaler` for the `RobustScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'robustscaler', 'pca', 'linearregression', 'robustscaler__copy', 'robustscaler__quantile_range', 'robustscaler__with_centering', 'robustscaler__with_scaling', 'pca__copy', 'pca__iterated_power', 'pca__n_components', 'pca__random_state', 'pca__svd_solver', 'pca__tol', 'pca__whiten', 'linearregression__copy_X', 'linearregression__fit_intercept', 'linearregression__n_jobs', 'linearregression__normalize'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_2 = make_pipeline(\n",
    "    RobustScaler(), \n",
    "    PCA(random_state=42),\n",
    "    LinearRegression() )\n",
    "pipe_2.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('robustscaler', RobustScaler()),\n",
       "                                       ('pca', PCA(random_state=42)),\n",
       "                                       ('linearregression',\n",
       "                                        LinearRegression())]),\n",
       "             param_grid={'pca__n_components': array([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_2 = {'pca__n_components': np.arange(4,20)}\n",
    "model_2 = GridSearchCV(pipe_2, param_grid_2, cv=5)\n",
    "model_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2: Best Score: 0.26785265231223887\n",
      "Model 2: Best Parameters: {'pca__n_components': 17}\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 2: Best Score: \" + str(model_2.best_score_))\n",
    "print(\"Model 2: Best Parameters: \" + str(model_2.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Model 3 - Robust Scaler, SelectKBest, Linear Regression<a id='6.3_Model_3_-_RobustScaler_SelectKBest_LinearRegression'></a>\n",
    "\n",
    "In our third model, we'll swap out `PCA` for `SelectKBest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'robustscaler', 'selectkbest', 'linearregression', 'robustscaler__copy', 'robustscaler__quantile_range', 'robustscaler__with_centering', 'robustscaler__with_scaling', 'selectkbest__k', 'selectkbest__score_func', 'linearregression__copy_X', 'linearregression__fit_intercept', 'linearregression__n_jobs', 'linearregression__normalize'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_3 = make_pipeline(\n",
    "    RobustScaler(), \n",
    "    SelectKBest(mutual_info_regression),\n",
    "    LinearRegression() )\n",
    "pipe_3.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('robustscaler', RobustScaler()),\n",
       "                                       ('selectkbest',\n",
       "                                        SelectKBest(score_func=<function mutual_info_regression at 0x000001727C56ECA0>)),\n",
       "                                       ('linearregression',\n",
       "                                        LinearRegression())]),\n",
       "             param_grid={'selectkbest__k': array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46,\n",
       "       47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59])})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_3 = {'selectkbest__k': np.arange(30,60) }\n",
    "model_3 = GridSearchCV(pipe_3, param_grid_3, cv=5)\n",
    "model_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3: Best Score: 0.3275323745682913\n",
      "Model 3: Best Parameters: {'selectkbest__k': 46}\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 3: Best Score: \" + str(model_3.best_score_))\n",
    "print(\"Model 3: Best Parameters: \" + str(model_3.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Model 4 - Robust Scaler, PCA, Random Forest<a id='6.4_Model_4_-_RobustScaler_PCA_RandomForest'></a>\n",
    "\n",
    "In the above models, we seem to have determined that the best number of components for PCA is 17. In the fourth model, we will swap out the `LinearRegressor` for `RandomForestRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'robustscaler', 'pca', 'randomforestregressor', 'robustscaler__copy', 'robustscaler__quantile_range', 'robustscaler__with_centering', 'robustscaler__with_scaling', 'pca__copy', 'pca__iterated_power', 'pca__n_components', 'pca__random_state', 'pca__svd_solver', 'pca__tol', 'pca__whiten', 'randomforestregressor__bootstrap', 'randomforestregressor__ccp_alpha', 'randomforestregressor__criterion', 'randomforestregressor__max_depth', 'randomforestregressor__max_features', 'randomforestregressor__max_leaf_nodes', 'randomforestregressor__max_samples', 'randomforestregressor__min_impurity_decrease', 'randomforestregressor__min_impurity_split', 'randomforestregressor__min_samples_leaf', 'randomforestregressor__min_samples_split', 'randomforestregressor__min_weight_fraction_leaf', 'randomforestregressor__n_estimators', 'randomforestregressor__n_jobs', 'randomforestregressor__oob_score', 'randomforestregressor__random_state', 'randomforestregressor__verbose', 'randomforestregressor__warm_start'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_4 = make_pipeline(\n",
    "    RobustScaler(), \n",
    "    PCA(random_state=42, n_components=17),\n",
    "    RandomForestRegressor(random_state=42) )\n",
    "pipe_4.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('robustscaler', RobustScaler()),\n",
       "                                       ('pca',\n",
       "                                        PCA(n_components=17, random_state=42)),\n",
       "                                       ('randomforestregressor',\n",
       "                                        RandomForestRegressor(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'randomforestregressor__max_depth': [2, 5, 10, 20],\n",
       "                         'randomforestregressor__n_estimators': [10, 31, 100,\n",
       "                                                                 316, 1000]})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_4 = {'randomforestregressor__n_estimators': [int(n) for n in np.logspace(start=1, stop=3, num=5)],\n",
    "                'randomforestregressor__max_depth': [2, 5, 10, 20]}\n",
    "model_4 = GridSearchCV(pipe_4, param_grid_4, cv=5, n_jobs=-1)\n",
    "model_4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4: Best Score: 0.46627746345200843\n",
      "Model 4: Best Parameters: {'randomforestregressor__max_depth': 20, 'randomforestregressor__n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 4: Best Score: \" + str(model_4.best_score_))\n",
    "print(\"Model 4: Best Parameters: \" + str(model_4.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Model 5 - Robust Scaler, PCA, Ridge<a id='6.5_Model_5_-_RobustScaler_PCA_Ridge'></a>\n",
    "\n",
    "Here we will try the `Ridge` regressor. We will increase the hyperparameter tuning for PCA since Ridge does better with more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'robustscaler', 'pca', 'ridge', 'robustscaler__copy', 'robustscaler__quantile_range', 'robustscaler__with_centering', 'robustscaler__with_scaling', 'pca__copy', 'pca__iterated_power', 'pca__n_components', 'pca__random_state', 'pca__svd_solver', 'pca__tol', 'pca__whiten', 'ridge__alpha', 'ridge__copy_X', 'ridge__fit_intercept', 'ridge__max_iter', 'ridge__normalize', 'ridge__random_state', 'ridge__solver', 'ridge__tol'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_5 = make_pipeline(\n",
    "    RobustScaler(), \n",
    "    PCA(random_state=42),\n",
    "    Ridge() )\n",
    "pipe_5.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('robustscaler', RobustScaler()),\n",
       "                                       ('pca', PCA(random_state=42)),\n",
       "                                       ('ridge', Ridge())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'pca__n_components': array([ 4,  8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68,\n",
       "       72, 76]),\n",
       "                         'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100, 300,\n",
       "                                          500, 1000]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_5 = {'pca__n_components': np.arange(4,80,4),\n",
    "                'ridge__alpha': [0.001, 0.01, 0.1, 1, 10, 100, 300, 500, 1000]}\n",
    "model_5 = GridSearchCV(pipe_5, param_grid_5, cv=5, n_jobs=-1)\n",
    "model_5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5: Best Score: 0.3266967615387865\n",
      "Model 5: Best Parameters: {'pca__n_components': 76, 'ridge__alpha': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 5: Best Score: \" + str(model_5.best_score_))\n",
    "print(\"Model 5: Best Parameters: \" + str(model_5.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Model 6 - Robust Scaler, PCA, Lasso<a id='6.6_Model_6_-_RobustScaler_PCA_Lasso'></a>\n",
    "\n",
    "Let's swap out `Ridge` for `Lasso`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'robustscaler', 'pca', 'lasso', 'robustscaler__copy', 'robustscaler__quantile_range', 'robustscaler__with_centering', 'robustscaler__with_scaling', 'pca__copy', 'pca__iterated_power', 'pca__n_components', 'pca__random_state', 'pca__svd_solver', 'pca__tol', 'pca__whiten', 'lasso__alpha', 'lasso__copy_X', 'lasso__fit_intercept', 'lasso__max_iter', 'lasso__normalize', 'lasso__positive', 'lasso__precompute', 'lasso__random_state', 'lasso__selection', 'lasso__tol', 'lasso__warm_start'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_6 = make_pipeline(\n",
    "    RobustScaler(), \n",
    "    PCA(random_state=42),\n",
    "    Lasso() )\n",
    "pipe_6.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('robustscaler', RobustScaler()),\n",
       "                                       ('pca', PCA(random_state=42)),\n",
       "                                       ('lasso', Lasso())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lasso__alpha': [0.1, 0.25, 0.5, 1, 5, 10],\n",
       "                         'pca__n_components': array([20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76])})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_6 = {'pca__n_components': np.arange(20,80,4),\n",
    "                'lasso__alpha': [0.1, 0.25, 0.5, 1, 5, 10]}\n",
    "model_6 = GridSearchCV(pipe_6, param_grid_6, cv=5, n_jobs=-1)\n",
    "model_6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6: Best Score: 0.32941407138721235\n",
      "Model 6: Best Parameters: {'lasso__alpha': 5, 'pca__n_components': 76}\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 6: Best Score: \" + str(model_6.best_score_))\n",
    "print(\"Model 6: Best Parameters: \" + str(model_6.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7 Model 7 - Robust Scaler, PCA, LassoLars<a id='6.7_Model_7_-_RobustScaler_PCA_LassoLars'></a>\n",
    "\n",
    "Let's swap out `Lasso` for `LassoLars`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'robustscaler', 'pca', 'lassolars', 'robustscaler__copy', 'robustscaler__quantile_range', 'robustscaler__with_centering', 'robustscaler__with_scaling', 'pca__copy', 'pca__iterated_power', 'pca__n_components', 'pca__random_state', 'pca__svd_solver', 'pca__tol', 'pca__whiten', 'lassolars__alpha', 'lassolars__copy_X', 'lassolars__eps', 'lassolars__fit_intercept', 'lassolars__fit_path', 'lassolars__jitter', 'lassolars__max_iter', 'lassolars__normalize', 'lassolars__positive', 'lassolars__precompute', 'lassolars__random_state', 'lassolars__verbose'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_7 = make_pipeline(\n",
    "    RobustScaler(), \n",
    "    PCA(random_state=42),\n",
    "    LassoLars() )\n",
    "pipe_7.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('robustscaler', RobustScaler()),\n",
       "                                       ('pca', PCA(random_state=42)),\n",
       "                                       ('lassolars', LassoLars())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lassolars__alpha': [0.1, 0.15, 0.25, 0.3, 0.5, 0.9],\n",
       "                         'pca__n_components': array([20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76])})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_7 = {'pca__n_components': np.arange(20,80,4),\n",
    "                'lassolars__alpha': [0.1, 0.15, 0.25, 0.3, 0.5, 0.9]}\n",
    "model_7 = GridSearchCV(pipe_7, param_grid_7, cv=5, n_jobs=-1)\n",
    "model_7.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 7: Best Score: 0.3257572758939543\n",
      "Model 7: Best Parameters: {'lassolars__alpha': 0.3, 'pca__n_components': 76}\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 7: Best Score: \" + str(model_7.best_score_))\n",
    "print(\"Model 7: Best Parameters: \" + str(model_7.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8 Model 8 - Robust Scaler, PCA, ElasticNet<a id='6.8_Model_8_-_RobustScaler_PCA_ElasticNet'></a>\n",
    "\n",
    "Let's try `ElasticNet`, should help with sparsity of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'robustscaler', 'pca', 'elasticnet', 'robustscaler__copy', 'robustscaler__quantile_range', 'robustscaler__with_centering', 'robustscaler__with_scaling', 'pca__copy', 'pca__iterated_power', 'pca__n_components', 'pca__random_state', 'pca__svd_solver', 'pca__tol', 'pca__whiten', 'elasticnet__alpha', 'elasticnet__copy_X', 'elasticnet__fit_intercept', 'elasticnet__l1_ratio', 'elasticnet__max_iter', 'elasticnet__normalize', 'elasticnet__positive', 'elasticnet__precompute', 'elasticnet__random_state', 'elasticnet__selection', 'elasticnet__tol', 'elasticnet__warm_start'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_8 = make_pipeline(\n",
    "    RobustScaler(), \n",
    "    PCA(random_state=42),\n",
    "    ElasticNet() )\n",
    "pipe_8.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('robustscaler', RobustScaler()),\n",
       "                                       ('pca', PCA(random_state=42)),\n",
       "                                       ('elasticnet', ElasticNet())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'elasticnet__alpha': [0.1, 0.15, 0.25, 0.3, 0.5, 0.9],\n",
       "                         'elasticnet__l1_ratio': [0.05, 0.1, 0.5, 0.7, 0.9,\n",
       "                                                  0.95, 0.99],\n",
       "                         'pca__n_components': array([20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76])})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_8 = {'pca__n_components': np.arange(20,80,4),\n",
    "                'elasticnet__alpha': [0.1, 0.15, 0.25, 0.3, 0.5, 0.9],\n",
    "                'elasticnet__l1_ratio': [0.05, 0.1, 0.5, 0.7, 0.9, 0.95, 0.99] }\n",
    "model_8 = GridSearchCV(pipe_8, param_grid_8, cv=5, n_jobs=-1)\n",
    "model_8.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 8: Best Score: 0.327975091308277\n",
      "Model 8: Best Parameters: {'elasticnet__alpha': 0.9, 'elasticnet__l1_ratio': 0.9, 'pca__n_components': 76}\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 8: Best Score: \" + str(model_8.best_score_))\n",
    "print(\"Model 8: Best Parameters: \" + str(model_8.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Model Evaluation<a id='7_Model_Evaluation'></a>\n",
    "\n",
    "Let's evaluate the models against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          R2(train)  R2(test)   MAE          SQRT(MSE)\n",
      "Model 1:  0.237608   0.273431   291.680729   386.709726\n",
      "Model 2:  0.267853   0.239206   298.509300   395.712791\n",
      "Model 3:  0.327532   0.091984   299.629686   432.308039\n",
      "Model 4:  0.466277   0.242836   282.534852   394.767824\n",
      "Model 5:  0.326697   0.292975   287.645985   381.473176\n",
      "Model 6:  0.329414   0.245116   293.949241   394.172812\n",
      "Model 7:  0.325757   0.175289   300.829798   412.000335\n",
      "Model 8:  0.327975   0.293744   287.554110   381.265704\n"
     ]
    }
   ],
   "source": [
    "models = [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8]\n",
    "print(\"          R2(train)  R2(test)   MAE          SQRT(MSE)\")\n",
    "for i, model in enumerate(models, start=1):\n",
    "    y_pred = model.best_estimator_.predict(X_test)\n",
    "    print(\"Model {}:  {:0.6f}   {:0.6f}   {:0,.6f}   {:0,.6f}\".format(i, model.best_score_, r2_score(y_test, y_pred), mean_absolute_error(y_test, y_pred), (mean_squared_error(y_test, y_pred))**0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these models are performing very well..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
